{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPe-5GhVi2RA"
      },
      "source": [
        "# WORKING MEMORY 2-BACK TASK: LSTM MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "je4-qzdVi2RD"
      },
      "source": [
        "## NMA DEEP LEARNING SUMMER SCHOOL\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_1t2pr-i2RE"
      },
      "source": [
        "The purpose of this study is to determine which key internal feature subset provides the greatest returns when forecasting the price of Bitcoin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vljqyUUzi2RF"
      },
      "outputs": [],
      "source": [
        "# Importing the Required Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Activation\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnMxwnTfi2RH"
      },
      "source": [
        "## Importing and Visualising the Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQfb3Cl_i2RI",
        "outputId": "a7cbbff3-1a51-40c9-f121-35c7444fee77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800000, 2)\n",
            "(240000, 2)\n"
          ]
        }
      ],
      "source": [
        "#Importing and visualising the training data\n",
        "imported_data_training = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/data_lr_balanced.csv\")\n",
        "print(imported_data_training.shape)\n",
        "\n",
        "#Importing and visualising the test data\n",
        "imported_data_test = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/data_lr_balanced_test(1).csv\")\n",
        "print(imported_data_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SiL6f1z-Bs1",
        "outputId": "77b5fe7f-ce48-4863-80f3-2e222c7126db"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRoXPTs8i2Rg"
      },
      "source": [
        "### All Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoQOPaMI7a9w",
        "outputId": "fd7e2c56-15d0-47d7-a3b6-b84688508bef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 10)                480       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,529\n",
            "Trainable params: 18,529\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "80000/80000 - 191s - loss: 0.6923 - accuracy: 0.5206 - 191s/epoch - 2ms/step\n",
            "Epoch 2/10\n",
            "80000/80000 - 187s - loss: 0.6923 - accuracy: 0.5207 - 187s/epoch - 2ms/step\n",
            "Epoch 3/10\n",
            "80000/80000 - 187s - loss: 0.6923 - accuracy: 0.5209 - 187s/epoch - 2ms/step\n",
            "Epoch 4/10\n",
            "80000/80000 - 186s - loss: 0.6923 - accuracy: 0.5208 - 186s/epoch - 2ms/step\n",
            "Epoch 5/10\n",
            "80000/80000 - 187s - loss: 0.6923 - accuracy: 0.5209 - 187s/epoch - 2ms/step\n",
            "Epoch 6/10\n",
            "80000/80000 - 185s - loss: 0.6923 - accuracy: 0.5207 - 185s/epoch - 2ms/step\n",
            "Epoch 7/10\n",
            "80000/80000 - 185s - loss: 0.6923 - accuracy: 0.5209 - 185s/epoch - 2ms/step\n",
            "Epoch 8/10\n",
            "80000/80000 - 185s - loss: 0.6923 - accuracy: 0.5208 - 185s/epoch - 2ms/step\n",
            "Epoch 9/10\n",
            "80000/80000 - 185s - loss: 0.6923 - accuracy: 0.5208 - 185s/epoch - 2ms/step\n",
            "Epoch 10/10\n",
            "80000/80000 - 185s - loss: 0.6923 - accuracy: 0.5207 - 185s/epoch - 2ms/step\n",
            "Accuracy: 52.14%\n"
          ]
        }
      ],
      "source": [
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "# prepare sequence\n",
        "length = 10\n",
        "training_data = imported_data_training.iloc[:,0:].values\n",
        "test_data = imported_data_test.iloc[:,0:].values\n",
        "X = training_data[:,0].reshape(len(training_data), 1)\n",
        "y = training_data[:,1].reshape(len(training_data), 1)\n",
        "\n",
        "X_test = test_data[:,0].reshape(len(test_data), 1)\n",
        "y_test = test_data[:,1].reshape(len(test_data), 1)\n",
        "\n",
        "\n",
        "# define LSTM configuration\n",
        "n_neurons = length\n",
        "n_batch = length\n",
        "n_epoch = 10\n",
        "# create LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(n_neurons, input_shape=(1, 1)))\n",
        "model.add(Dense(128))\n",
        "model.add(Dense(128))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "# train LSTM\n",
        "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=2)\n",
        "# evaluate\n",
        "#result = model.predict(X_test)\n",
        "\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pcjYjSb9DPTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P_9blqb4Bbid"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4d6_iyng--3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5362a5d-1ed4-4d2d-fed9-f962449360f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 52.14%\n"
          ]
        }
      ],
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Pl0rGmFv_MZA"
      },
      "outputs": [],
      "source": [
        "result = model.predict(X_test, batch_size=n_batch, verbose =0)\n",
        "result = np.round(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HWacsBHP_PTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b693916c-ae04-4caf-9e5b-03ffa4547bd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stimuli [2] result: [0.] y test: [0]\n",
            "stimuli [0] result: [0.] y test: [0]\n",
            "stimuli [4] result: [0.] y test: [0]\n",
            "stimuli [0] result: [0.] y test: [1]\n",
            "stimuli [4] result: [0.] y test: [1]\n",
            "stimuli [0] result: [0.] y test: [1]\n",
            "stimuli [2] result: [0.] y test: [0]\n",
            "stimuli [1] result: [0.] y test: [0]\n",
            "stimuli [2] result: [0.] y test: [1]\n",
            "stimuli [5] result: [0.] y test: [0]\n",
            "stimuli [2] result: [0.] y test: [1]\n",
            "stimuli [5] result: [0.] y test: [1]\n",
            "stimuli [4] result: [0.] y test: [0]\n",
            "stimuli [4] result: [0.] y test: [0]\n",
            "stimuli [4] result: [0.] y test: [1]\n",
            "stimuli [4] result: [0.] y test: [1]\n",
            "stimuli [4] result: [0.] y test: [1]\n",
            "stimuli [2] result: [0.] y test: [0]\n",
            "stimuli [2] result: [0.] y test: [0]\n",
            "stimuli [2] result: [0.] y test: [1]\n",
            "stimuli [3] result: [0.] y test: [0]\n",
            "stimuli [3] result: [0.] y test: [0]\n",
            "stimuli [3] result: [0.] y test: [1]\n",
            "stimuli [3] result: [0.] y test: [1]\n",
            "stimuli [3] result: [0.] y test: [1]\n",
            "stimuli [1] result: [0.] y test: [0]\n",
            "stimuli [3] result: [0.] y test: [1]\n",
            "stimuli [5] result: [0.] y test: [0]\n",
            "stimuli [5] result: [0.] y test: [0]\n",
            "stimuli [1] result: [0.] y test: [0]\n",
            "stimuli [3] result: [0.] y test: [0]\n",
            "stimuli [1] result: [0.] y test: [1]\n"
          ]
        }
      ],
      "source": [
        "#print(y_test[:100])\n",
        "unique, counts = np.unique(result, return_counts=True)\n",
        "dict(zip(unique, counts))\n",
        "\n",
        "for i in range (32):\n",
        "  print(\"stimuli\", X_test[i],\"result:\", result[i], \"y test:\", y_test[i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`MANY-TO-MANY (32)`"
      ],
      "metadata": {
        "id": "ZWk4hbtbvEiw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ba20a2e-75e5-4b37-f03b-0dc735f5bdb0",
        "id": "2sE_kFpdMf3u"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_3 (LSTM)               (None, 32, 10)            480       \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 32, 128)          1408      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 32, 128)          16512     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 32, 1)            129       \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,529\n",
            "Trainable params: 18,529\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "25000/25000 - 73s - loss: 0.1648 - accuracy: 0.9283 - 73s/epoch - 3ms/step\n",
            "Epoch 2/10\n",
            "25000/25000 - 70s - loss: 0.0506 - accuracy: 0.9831 - 70s/epoch - 3ms/step\n",
            "Epoch 3/10\n",
            "25000/25000 - 71s - loss: 0.0406 - accuracy: 0.9864 - 71s/epoch - 3ms/step\n",
            "Epoch 4/10\n",
            "25000/25000 - 70s - loss: 0.0365 - accuracy: 0.9877 - 70s/epoch - 3ms/step\n",
            "Epoch 5/10\n",
            "25000/25000 - 71s - loss: 0.0339 - accuracy: 0.9885 - 71s/epoch - 3ms/step\n",
            "Epoch 6/10\n",
            "25000/25000 - 70s - loss: 0.0322 - accuracy: 0.9889 - 70s/epoch - 3ms/step\n",
            "Epoch 7/10\n",
            "25000/25000 - 71s - loss: 0.0310 - accuracy: 0.9892 - 71s/epoch - 3ms/step\n",
            "Epoch 8/10\n",
            "25000/25000 - 70s - loss: 0.0302 - accuracy: 0.9894 - 70s/epoch - 3ms/step\n",
            "Epoch 9/10\n",
            "25000/25000 - 71s - loss: 0.0296 - accuracy: 0.9895 - 71s/epoch - 3ms/step\n",
            "Epoch 10/10\n",
            "25000/25000 - 70s - loss: 0.0293 - accuracy: 0.9896 - 70s/epoch - 3ms/step\n",
            "Accuracy: 98.95%\n"
          ]
        }
      ],
      "source": [
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "# prepare sequence\n",
        "length = 10\n",
        "training_data = imported_data_training.iloc[:,0:].values\n",
        "test_data = imported_data_test.iloc[:,0:].values\n",
        "\n",
        "\n",
        "X = training_data[:,0].reshape(25000,32, 1)\n",
        "y = training_data[:,1].reshape(25000,32, 1)\n",
        "\n",
        "X_test = test_data[:,0].reshape(7500,32, 1)\n",
        "y_test = test_data[:,1].reshape(7500,32, 1)\n",
        "\n",
        "# define LSTM configuration\n",
        "n_neurons = 10\n",
        "n_batch = 1\n",
        "n_epoch = 10\n",
        "# create LSTM\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(n_neurons, input_shape=(32, 1), return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(128)))\n",
        "model.add(TimeDistributed(Dense(128)))\n",
        "model.add(TimeDistributed(Dense(1,activation='sigmoid')))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "# train LSTM\n",
        "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=2)\n",
        "# evaluate\n",
        "#result = model.predict(X_test)\n",
        "\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(scores[1])\n",
        "result = model.predict(X_test, batch_size=n_batch, verbose =0)\n",
        "result = np.round(result)\n",
        "\n",
        "for i in range (32):\n",
        "  print(\"stimuli\", X_test[5,i],\"result:\", result[5,i], \"y test:\", y_test[5,i])\n",
        "\n",
        "unique, counts = np.unique(result, return_counts=True)\n",
        "dict(zip(unique, counts))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjD0mQ_CSeF2",
        "outputId": "fab539f1-194b-4e58-b8b5-0441b2621134"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9894541501998901\n",
            "stimuli [5] result: [0.] y test: [0]\n",
            "stimuli [5] result: [0.] y test: [1]\n",
            "stimuli [1] result: [0.] y test: [0]\n",
            "stimuli [5] result: [1.] y test: [1]\n",
            "stimuli [2] result: [0.] y test: [0]\n",
            "stimuli [2] result: [0.] y test: [0]\n",
            "stimuli [2] result: [1.] y test: [1]\n",
            "stimuli [2] result: [1.] y test: [1]\n",
            "stimuli [0] result: [0.] y test: [0]\n",
            "stimuli [2] result: [1.] y test: [1]\n",
            "stimuli [0] result: [1.] y test: [1]\n",
            "stimuli [2] result: [1.] y test: [1]\n",
            "stimuli [3] result: [0.] y test: [0]\n",
            "stimuli [2] result: [1.] y test: [1]\n",
            "stimuli [3] result: [1.] y test: [1]\n",
            "stimuli [0] result: [0.] y test: [0]\n",
            "stimuli [0] result: [0.] y test: [0]\n",
            "stimuli [4] result: [0.] y test: [0]\n",
            "stimuli [4] result: [0.] y test: [0]\n",
            "stimuli [4] result: [1.] y test: [1]\n",
            "stimuli [4] result: [1.] y test: [1]\n",
            "stimuli [4] result: [1.] y test: [1]\n",
            "stimuli [5] result: [0.] y test: [0]\n",
            "stimuli [1] result: [0.] y test: [0]\n",
            "stimuli [0] result: [0.] y test: [0]\n",
            "stimuli [1] result: [1.] y test: [1]\n",
            "stimuli [0] result: [1.] y test: [1]\n",
            "stimuli [1] result: [1.] y test: [1]\n",
            "stimuli [0] result: [1.] y test: [1]\n",
            "stimuli [5] result: [0.] y test: [0]\n",
            "stimuli [4] result: [0.] y test: [0]\n",
            "stimuli [5] result: [1.] y test: [1]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.0: 127664, 1.0: 112336}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Mohinga Project _ LSTM.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}